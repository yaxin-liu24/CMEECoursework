# Final CMEE Bootcamp Assessment: Yaxin

1. **Week 1:**
   -  Well-organized directories: `code`, `data`, `results`, and `sandbox`.
   - The README lacked detailed installation and usage instructions, though it briefly described the project.
   - Output from scripts like `csvtospace.sh` pointed out a missing `usage` function.
  - Scripts like `csvtospace.sh` referenced a missing `usage` function, causing runtime errors. 

2. **Week 2:**
   - The README became more detailed, with clearer descriptions of project dependencies and installation steps.
   - Some Python scripts lacked proper docstrings or script-level descriptions.
  - Python scripts like `lc2.py` showcased basic understanding of list comprehensions and loops, but not modified from baselines provided.
  - You could have formatted the output of scripts to be a more neat /  organised / informative -- for example `lc1.py` is perfectly functional, but the output could have been improved (compare with my solution). 
  - Several scripts, including `basic_io1.py`, lacked docstrings. Adding these would have helped and maintainability.
  - Avoid unnecessary comments for standard library functions.

3. **Week 3:**
   -  The README expanded to include details about specific R scripts like `Florida.R` and `PP_Regress.R`. The project structure was consistent.
   - Results directories were clean, and proper file organization ensured minimal clutter.
   - Missing package installations, such as `dplyr`, caused errors in testing.
  - Early weeks lacked depth in describing the projectâ€™s purpose and dependencies.
  - By Week 3, README files contained detailed information, including commands for running scripts, dependencies, and expected outputs.
  - Add example commands with inputs and outputs for users unfamiliar with the project.
  - Mention the minimum required versions of tools like Python, R, and package dependencies.
  - Functions could be modularized for better reuse. For example, `TreeHeight.R` could split data processing and calculations into separate functions.

**Week 4:**
   - Clear enough explanations of statistical methods, but lacking depth.
   - Ensure all references (e.g., `Florida.pdf`) are generated before compiling the LaTeX document.
   - Your Autocorrelation practicals were OK, with some tweaks needed - please compare your p-value calculations with the solutions provided. The code was succinct and it was reasonably efficient . Include inline comments to explain the purpose of each statistical test.
    - Your statistical and biological/ecological interpretations could have been more succinct / insightful. The report's conclusion was somewhat ambiguous at the end.
    - Your Groupwork practicals were all in order, and your group did OK in collaborating  - have a look at my group-specific feedback (already pushed to the git repo).


### Git Practices

- Early commits lacked descriptive messages (e.g., "new changes").
- By Week 2, commit messages became slightly clearer, but more detail was needed to describe the purpose of changes.
- Merge conflicts were successfully resolved, demonstrating increasing with version control.
- Use descriptive commit messages that explain the changes.
- *Repository size was at ~2.34 MiB, indicating good practices in managing file types.

### Overall Assessment

Overall, a good job! 

You demonstrated consistent improvement in project organization, coding practices, and documentation over four weeks. moving forward, focus on modularizing code, improving documentation, and writing descriptive git commit messages. Some of your scripts did retain errors. Try to be a little more vigilant in chasing down errors in future. Your commenting is very thorough, perhaps a little too much so, but this is also likely to be a tendency that fixes itself with experience.

It was a tough set of weeks, but I believe your hard work in them has given you a great start towards further training, a quantitative masters dissertation, and ultimately a career in quantitative biology! 
---

### (Provisional) Mark
 
 *68*