{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:36:48.598716Z",
     "iopub.status.busy": "2025-03-14T13:36:48.598294Z",
     "iopub.status.idle": "2025-03-14T13:36:52.015663Z",
     "shell.execute_reply": "2025-03-14T13:36:52.015340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Number of successful NLLS quadratic fits: 247 / 285\n",
      " Fit parameters saved to: ../results/nlls_quadratic_fits.csv\n",
      " Fit plots saved to: ../results/quadratic_plots (only for the first 5 successful fits)\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lmfit import Minimizer, Parameters\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load data\n",
    "data_path = \"../data/LogisticGrowthData_Cleaned.csv\"\n",
    "results_path = \"../results\"\n",
    "plots_path = os.path.join(results_path, \"quadratic_plots\")\n",
    "\n",
    "# Ensure result storage directories exist\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "os.makedirs(plots_path, exist_ok=True)\n",
    "\n",
    "# Read data\n",
    "data_filtered = pd.read_csv(data_path)\n",
    "\n",
    "# Get all subset IDs\n",
    "subset_list = data_filtered[\"ID\"].unique()\n",
    "fit_results = []  # Store fit parameters and R²\n",
    "successful_fits = []\n",
    "\n",
    "# Process ID to prevent excessively long filenames\n",
    "def sanitize_filename(text, max_length=50):\n",
    "    \"\"\"Clean filename by removing special characters and limiting length.\"\"\"\n",
    "    text = \"\".join(c if c.isalnum() or c in \"_-\" else \"_\" for c in text)\n",
    "    if len(text) > max_length:\n",
    "        text = text[:max_length]\n",
    "        hash_suffix = hashlib.md5(text.encode()).hexdigest()[:8]\n",
    "        text += f\"_{hash_suffix}\"\n",
    "    return text\n",
    "\n",
    "# Define NLLS objective function\n",
    "def residuals_quadratic(params, t, data):\n",
    "    \"\"\"Compute residuals for quadratic model.\"\"\"\n",
    "    v = params.valuesdict()\n",
    "    model = v['a'] * t**2 + v['b'] * t + v['c']\n",
    "    return model - data\n",
    "\n",
    "# Iterate over all subsets for NLLS fitting\n",
    "for subset_id in subset_list:\n",
    "    subset_data = data_filtered[data_filtered[\"ID\"] == subset_id]\n",
    "\n",
    "    # Skip if too few data points\n",
    "    if len(subset_data) < 5:\n",
    "        continue\n",
    "\n",
    "    t = subset_data[\"Time\"].values\n",
    "    N_obs = subset_data[\"PopBio\"].values\n",
    "\n",
    "    # Compute OLS as initial values\n",
    "    X_ols = np.vstack([t**2, t, np.ones_like(t)]).T\n",
    "    ols_model = LinearRegression(fit_intercept=False)\n",
    "    ols_model.fit(X_ols, N_obs)\n",
    "    a_start, b_start, c_start = ols_model.coef_\n",
    "\n",
    "    # Create parameter object\n",
    "    params_quadratic = Parameters()\n",
    "    params_quadratic.add('a', value=a_start)\n",
    "    params_quadratic.add('b', value=b_start)\n",
    "    params_quadratic.add('c', value=c_start)\n",
    "\n",
    "    # Perform NLLS fitting\n",
    "    minner = Minimizer(residuals_quadratic, params_quadratic, fcn_args=(t, N_obs))\n",
    "    fit_quadratic_NLLS = minner.minimize()\n",
    "\n",
    "    # Compute R²\n",
    "    v_fit = fit_quadratic_NLLS.params.valuesdict()\n",
    "    N_fit = v_fit['a'] * t**2 + v_fit['b'] * t + v_fit['c']\n",
    "\n",
    "    ss_res = np.sum((N_obs - N_fit) ** 2)\n",
    "    ss_tot = np.sum((N_obs - np.mean(N_obs)) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "\n",
    "    # Store fit parameters and R²\n",
    "    fit_results.append({\n",
    "        \"ID\": subset_id,\n",
    "        \"a\": v_fit['a'],\n",
    "        \"b\": v_fit['b'],\n",
    "        \"c\": v_fit['c'],\n",
    "        \"R²\": r2\n",
    "    })\n",
    "\n",
    "    if r2 > 0.6:\n",
    "        successful_fits.append(subset_id)\n",
    "\n",
    "    # Generate and save fit plots (only for the first 5 successful fits)\n",
    "    if len(successful_fits) <= 5:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(t, N_obs, label=\"Observed Data\", color='blue', alpha=0.6)\n",
    "\n",
    "        t_fine = np.linspace(min(t), max(t), 100)\n",
    "        N_fine = v_fit['a'] * t_fine**2 + v_fit['b'] * t_fine + v_fit['c']\n",
    "\n",
    "        plt.plot(t_fine, N_fine, label=f\"NLLS Fit (R²={r2:.3f})\", color='red', linewidth=2)\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"PopBio\")\n",
    "        plt.title(f\"NLLS Quadratic Fit for ID: {subset_id[:30]}...\")\n",
    "        plt.legend()\n",
    "\n",
    "        # Modify filename to prevent excessive length\n",
    "        safe_id = sanitize_filename(subset_id)\n",
    "        plot_filename = os.path.join(plots_path, f\"fit_ID_{safe_id}.png\")\n",
    "        plt.savefig(plot_filename, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "# Save fit parameters to CSV\n",
    "fit_results_df = pd.DataFrame(fit_results)\n",
    "fit_results_df.to_csv(os.path.join(results_path, \"nlls_quadratic_fits.csv\"), index=False)\n",
    "\n",
    "# Output successful fit count\n",
    "print(f\"\\n Number of successful NLLS quadratic fits: {len(successful_fits)} / {len(subset_list)}\")\n",
    "print(f\" Fit parameters saved to: {results_path}/nlls_quadratic_fits.csv\")\n",
    "print(f\" Fit plots saved to: {plots_path} (only for the first 5 successful fits)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:36:52.041985Z",
     "iopub.status.busy": "2025-03-14T13:36:52.041819Z",
     "iopub.status.idle": "2025-03-14T13:36:54.107716Z",
     "shell.execute_reply": "2025-03-14T13:36:54.107372Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1240: RuntimeWarning: divide by zero encountered in divide\n",
      "  a = -(dx2)/(dx1 * (dx1 + dx2))\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1241: RuntimeWarning: divide by zero encountered in divide\n",
      "  b = (dx2 - dx1) / (dx1 * dx2)\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1242: RuntimeWarning: divide by zero encountered in divide\n",
      "  c = dx1 / (dx2 * (dx1 + dx2))\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1248: RuntimeWarning: invalid value encountered in add\n",
      "  out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1240: RuntimeWarning: divide by zero encountered in divide\n",
      "  a = -(dx2)/(dx1 * (dx1 + dx2))\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1241: RuntimeWarning: divide by zero encountered in divide\n",
      "  b = (dx2 - dx1) / (dx1 * dx2)\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1242: RuntimeWarning: divide by zero encountered in divide\n",
      "  c = dx1 / (dx2 * (dx1 + dx2))\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1248: RuntimeWarning: invalid value encountered in add\n",
      "  out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1240: RuntimeWarning: invalid value encountered in divide\n",
      "  a = -(dx2)/(dx1 * (dx1 + dx2))\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1241: RuntimeWarning: divide by zero encountered in divide\n",
      "  b = (dx2 - dx1) / (dx1 * dx2)\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1241: RuntimeWarning: invalid value encountered in divide\n",
      "  b = (dx2 - dx1) / (dx1 * dx2)\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1242: RuntimeWarning: divide by zero encountered in divide\n",
      "  c = dx1 / (dx2 * (dx1 + dx2))\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1242: RuntimeWarning: invalid value encountered in divide\n",
      "  c = dx1 / (dx2 * (dx1 + dx2))\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1248: RuntimeWarning: invalid value encountered in add\n",
      "  out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1264: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_n\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1240: RuntimeWarning: divide by zero encountered in divide\n",
      "  a = -(dx2)/(dx1 * (dx1 + dx2))\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1241: RuntimeWarning: divide by zero encountered in divide\n",
      "  b = (dx2 - dx1) / (dx1 * dx2)\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1242: RuntimeWarning: divide by zero encountered in divide\n",
      "  c = dx1 / (dx2 * (dx1 + dx2))\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1248: RuntimeWarning: invalid value encountered in add\n",
      "  out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Number of successful two-stage NLLS quadratic fits: 261 / 285\n",
      " Fit parameters saved to: ../results/two_stage_quadratic_fits.csv\n",
      " Fit plots saved to: ../results/two_stage_quadratic_plots (only for the first 5 successful fits)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lmfit import Minimizer, Parameters\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load data\n",
    "data_path = \"../data/LogisticGrowthData_Cleaned.csv\"\n",
    "results_path = \"../results\"\n",
    "plots_path = os.path.join(results_path, \"two_stage_quadratic_plots\")\n",
    "\n",
    "# Ensure storage directories exist\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "os.makedirs(plots_path, exist_ok=True)\n",
    "\n",
    "# Read data\n",
    "data_filtered = pd.read_csv(data_path)\n",
    "\n",
    "# Get all subset IDs\n",
    "subset_list = data_filtered[\"ID\"].unique()\n",
    "successful_fits = []\n",
    "fit_results = []\n",
    "max_plots = 5  # Limit number of plots\n",
    "plot_count = 0  \n",
    "\n",
    "# Process filename\n",
    "def sanitize_filename(text, max_length=50):\n",
    "    \"\"\"Clean filename by removing special characters and limiting length.\"\"\"\n",
    "    text = \"\".join(c if c.isalnum() or c in \"_-\" else \"_\" for c in text)\n",
    "    if len(text) > max_length:\n",
    "        text = text[:max_length]\n",
    "        hash_suffix = hashlib.md5(text.encode()).hexdigest()[:8]\n",
    "        text += f\"_{hash_suffix}\"\n",
    "    return text\n",
    "\n",
    "# Define NLLS objective function\n",
    "def residuals_quadratic(params, t, data):\n",
    "    \"\"\"Compute residuals for quadratic model.\"\"\"\n",
    "    v = params.valuesdict()\n",
    "    model = v['a'] * t**2 + v['b'] * t + v['c']\n",
    "    return model - data\n",
    "\n",
    "# Split data into two phases\n",
    "def split_into_two_phases(subset_data):\n",
    "    \"\"\"Identify the point of highest rate change and split into two phases.\"\"\"\n",
    "    if len(subset_data) < 5:\n",
    "        return [subset_data]\n",
    "    \n",
    "    t = subset_data[\"Time\"].values\n",
    "    y = subset_data[\"PopBio\"].values\n",
    "    dydt = np.gradient(y, t)\n",
    "    \n",
    "    split_index = np.argmax(np.abs(np.gradient(dydt)))\n",
    "    \n",
    "    if split_index < 2 or split_index > len(t) - 3:\n",
    "        return [subset_data]\n",
    "    \n",
    "    phase_1 = subset_data.iloc[:split_index+1]\n",
    "    phase_2 = subset_data.iloc[split_index:]\n",
    "    \n",
    "    return [phase_1, phase_2]\n",
    "\n",
    "# Iterate over all subsets for NLLS fitting\n",
    "for subset_id in subset_list:\n",
    "    subset_data = data_filtered[data_filtered[\"ID\"] == subset_id]\n",
    "    if len(subset_data) < 5:\n",
    "        continue\n",
    "\n",
    "    phases = split_into_two_phases(subset_data)\n",
    "    \n",
    "    overall_r2 = 0\n",
    "    phase_models = []\n",
    "\n",
    "    for i, phase in enumerate(phases):\n",
    "        if len(phase) < 4:\n",
    "            continue\n",
    "\n",
    "        t = phase[\"Time\"].values\n",
    "        N_obs = phase[\"PopBio\"].values\n",
    "\n",
    "        # Compute OLS initial values\n",
    "        X_ols = np.vstack([t**2, t, np.ones_like(t)]).T\n",
    "        ols_model = LinearRegression(fit_intercept=False)\n",
    "        ols_model.fit(X_ols, N_obs)\n",
    "        a_start, b_start, c_start = ols_model.coef_\n",
    "\n",
    "        # Create parameter object\n",
    "        params_quadratic = Parameters()\n",
    "        params_quadratic.add('a', value=a_start)\n",
    "        params_quadratic.add('b', value=b_start)\n",
    "        params_quadratic.add('c', value=c_start)\n",
    "\n",
    "        # Perform NLLS fitting\n",
    "        minner = Minimizer(residuals_quadratic, params_quadratic, fcn_args=(t, N_obs))\n",
    "        fit_quadratic_NLLS = minner.minimize()\n",
    "\n",
    "        # Compute R²\n",
    "        v_fit = fit_quadratic_NLLS.params.valuesdict()\n",
    "        N_fit = v_fit['a'] * t**2 + v_fit['b'] * t + v_fit['c']\n",
    "        \n",
    "        ss_res = np.sum((N_obs - N_fit) ** 2)\n",
    "        ss_tot = np.sum((N_obs - np.mean(N_obs)) ** 2)\n",
    "        r2 = 1 - (ss_res / ss_tot)\n",
    "\n",
    "        if r2 > 0.6:\n",
    "            overall_r2 += r2\n",
    "            phase_models.append((t, N_obs, v_fit, r2))\n",
    "            \n",
    "            fit_results.append({\n",
    "                \"ID\": subset_id,\n",
    "                \"Phase\": i+1,\n",
    "                \"a\": v_fit['a'],\n",
    "                \"b\": v_fit['b'],\n",
    "                \"c\": v_fit['c'],\n",
    "                \"R²\": r2\n",
    "            })\n",
    "\n",
    "    # Evaluate overall fit result\n",
    "    if len(phase_models) > 0:\n",
    "        avg_r2 = overall_r2 / len(phase_models)\n",
    "        if avg_r2 > 0.6:\n",
    "            successful_fits.append(subset_id)\n",
    "\n",
    "            # Generate plots for first 5 successful subsets\n",
    "            if plot_count < max_plots:\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                colors = ['blue', 'green']\n",
    "                for j, (t, N_obs, v_fit, r2) in enumerate(phase_models):\n",
    "                    plt.scatter(t, N_obs, label=f\"Phase {j+1} Data\", color=colors[j % len(colors)], alpha=0.6)\n",
    "                    t_fine = np.linspace(min(t), max(t), 100)\n",
    "                    N_fine = v_fit['a'] * t_fine**2 + v_fit['b'] * t_fine + v_fit['c']\n",
    "                    plt.plot(t_fine, N_fine, label=f\"Phase {j+1} (R²={r2:.3f})\", color=colors[j % len(colors)], linewidth=2)\n",
    "                    \n",
    "                plt.xlabel(\"Time\")\n",
    "                plt.ylabel(\"PopBio\")\n",
    "                plt.title(f\"NLLS Quadratic Fit for ID: {subset_id[:30]}... (Avg R²={avg_r2:.3f})\")\n",
    "                plt.legend()\n",
    "\n",
    "                safe_id = sanitize_filename(subset_id)\n",
    "                plot_filename = os.path.join(plots_path, f\"fit_ID_{safe_id}.png\")\n",
    "                plt.savefig(plot_filename, dpi=300)\n",
    "                plt.close()\n",
    "\n",
    "                plot_count += 1\n",
    "\n",
    "# Save fit parameters to CSV\n",
    "fit_results_df = pd.DataFrame(fit_results)\n",
    "fit_results_df.to_csv(os.path.join(results_path, \"two_stage_quadratic_fits.csv\"), index=False)\n",
    "\n",
    "# Output successful fit count\n",
    "print(f\"\\n Number of successful two-stage NLLS quadratic fits: {len(successful_fits)} / {len(subset_list)}\")\n",
    "print(f\" Fit parameters saved to: {results_path}/two_stage_quadratic_fits.csv\")\n",
    "print(f\" Fit plots saved to: {plots_path} (only for the first 5 successful fits)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:36:54.109677Z",
     "iopub.status.busy": "2025-03-14T13:36:54.109512Z",
     "iopub.status.idle": "2025-03-14T13:36:56.198369Z",
     "shell.execute_reply": "2025-03-14T13:36:56.198037Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1240: RuntimeWarning: divide by zero encountered in divide\n",
      "  a = -(dx2)/(dx1 * (dx1 + dx2))\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1241: RuntimeWarning: divide by zero encountered in divide\n",
      "  b = (dx2 - dx1) / (dx1 * dx2)\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1242: RuntimeWarning: divide by zero encountered in divide\n",
      "  c = dx1 / (dx2 * (dx1 + dx2))\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1248: RuntimeWarning: invalid value encountered in add\n",
      "  out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1240: RuntimeWarning: divide by zero encountered in divide\n",
      "  a = -(dx2)/(dx1 * (dx1 + dx2))\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1241: RuntimeWarning: divide by zero encountered in divide\n",
      "  b = (dx2 - dx1) / (dx1 * dx2)\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1242: RuntimeWarning: divide by zero encountered in divide\n",
      "  c = dx1 / (dx2 * (dx1 + dx2))\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1248: RuntimeWarning: invalid value encountered in add\n",
      "  out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1240: RuntimeWarning: invalid value encountered in divide\n",
      "  a = -(dx2)/(dx1 * (dx1 + dx2))\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1241: RuntimeWarning: divide by zero encountered in divide\n",
      "  b = (dx2 - dx1) / (dx1 * dx2)\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1241: RuntimeWarning: invalid value encountered in divide\n",
      "  b = (dx2 - dx1) / (dx1 * dx2)\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1242: RuntimeWarning: divide by zero encountered in divide\n",
      "  c = dx1 / (dx2 * (dx1 + dx2))\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1242: RuntimeWarning: invalid value encountered in divide\n",
      "  c = dx1 / (dx2 * (dx1 + dx2))\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1248: RuntimeWarning: invalid value encountered in add\n",
      "  out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1264: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  out[tuple(slice1)] = (f[tuple(slice2)] - f[tuple(slice3)]) / dx_n\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1240: RuntimeWarning: divide by zero encountered in divide\n",
      "  a = -(dx2)/(dx1 * (dx1 + dx2))\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1241: RuntimeWarning: divide by zero encountered in divide\n",
      "  b = (dx2 - dx1) / (dx1 * dx2)\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1242: RuntimeWarning: divide by zero encountered in divide\n",
      "  c = dx1 / (dx2 * (dx1 + dx2))\n",
      "/Users/auroraliu/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:1248: RuntimeWarning: invalid value encountered in add\n",
      "  out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Number of successful two-stage NLLS cubic fits: 268 / 285\n",
      " Fit parameters saved to: ../results/nlls_cubic_fits.csv.csv\n",
      " Fit plots saved to: ../results/cubic_plots (only for the first 5 successful fits)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lmfit import Minimizer, Parameters\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load data\n",
    "data_path = \"../data/LogisticGrowthData_Cleaned.csv\"\n",
    "results_path = \"../results\"\n",
    "plots_path = os.path.join(results_path, \"cubic_plots\")\n",
    "\n",
    "# Ensure storage directories exist\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "os.makedirs(plots_path, exist_ok=True)\n",
    "\n",
    "# Read data\n",
    "data_filtered = pd.read_csv(data_path)\n",
    "\n",
    "# Get all subset IDs\n",
    "subset_list = data_filtered[\"ID\"].unique()\n",
    "successful_fits = []\n",
    "fit_results = []\n",
    "max_plots = 5  # Limit number of plots\n",
    "plot_count = 0  \n",
    "\n",
    "# Process filename\n",
    "def sanitize_filename(text, max_length=50):\n",
    "    \"\"\"Clean filename by removing special characters and limiting length.\"\"\"\n",
    "    text = \"\".join(c if c.isalnum() or c in \"_-\" else \"_\" for c in text)\n",
    "    if len(text) > max_length:\n",
    "        text = text[:max_length]\n",
    "        hash_suffix = hashlib.md5(text.encode()).hexdigest()[:8]\n",
    "        text += f\"_{hash_suffix}\"\n",
    "    return text\n",
    "\n",
    "# Define NLLS objective function (Cubic)\n",
    "def residuals_cubic(params, t, data):\n",
    "    \"\"\"Compute residuals for cubic model.\"\"\"\n",
    "    v = params.valuesdict()\n",
    "    model = v['a'] * t**3 + v['b'] * t**2 + v['c'] * t + v['d']\n",
    "    return model - data\n",
    "\n",
    "# Split data into two phases\n",
    "def split_into_two_phases(subset_data):\n",
    "    \"\"\"Identify the point of highest rate change and split into two phases.\"\"\"\n",
    "    if len(subset_data) < 5:\n",
    "        return [subset_data]\n",
    "    \n",
    "    t = subset_data[\"Time\"].values\n",
    "    y = subset_data[\"PopBio\"].values\n",
    "    dydt = np.gradient(y, t)\n",
    "    \n",
    "    split_index = np.argmax(np.abs(np.gradient(dydt)))\n",
    "    \n",
    "    if split_index < 2 or split_index > len(t) - 3:\n",
    "        return [subset_data]\n",
    "    \n",
    "    phase_1 = subset_data.iloc[:split_index+1]\n",
    "    phase_2 = subset_data.iloc[split_index:]\n",
    "    \n",
    "    return [phase_1, phase_2]\n",
    "\n",
    "# Iterate over all subsets for NLLS fitting\n",
    "for subset_id in subset_list:\n",
    "    subset_data = data_filtered[data_filtered[\"ID\"] == subset_id]\n",
    "    if len(subset_data) < 5:\n",
    "        continue\n",
    "\n",
    "    phases = split_into_two_phases(subset_data)\n",
    "    \n",
    "    overall_r2 = 0\n",
    "    phase_models = []\n",
    "\n",
    "    for i, phase in enumerate(phases):\n",
    "        if len(phase) < 4:\n",
    "            continue\n",
    "\n",
    "        t = phase[\"Time\"].values\n",
    "        N_obs = phase[\"PopBio\"].values\n",
    "\n",
    "        # Compute OLS initial values\n",
    "        X_ols = np.vstack([t**3, t**2, t, np.ones_like(t)]).T\n",
    "        ols_model = LinearRegression(fit_intercept=False)\n",
    "        ols_model.fit(X_ols, N_obs)\n",
    "        a_start, b_start, c_start, d_start = ols_model.coef_\n",
    "\n",
    "        # Create parameter object\n",
    "        params_cubic = Parameters()\n",
    "        params_cubic.add('a', value=a_start)\n",
    "        params_cubic.add('b', value=b_start)\n",
    "        params_cubic.add('c', value=c_start)\n",
    "        params_cubic.add('d', value=d_start)\n",
    "\n",
    "        # Perform NLLS fitting\n",
    "        minner = Minimizer(residuals_cubic, params_cubic, fcn_args=(t, N_obs))\n",
    "        fit_cubic_NLLS = minner.minimize()\n",
    "\n",
    "        # Compute R²\n",
    "        v_fit = fit_cubic_NLLS.params.valuesdict()\n",
    "        N_fit = v_fit['a'] * t**3 + v_fit['b'] * t**2 + v_fit['c'] * t + v_fit['d']\n",
    "        \n",
    "        ss_res = np.sum((N_obs - N_fit) ** 2)\n",
    "        ss_tot = np.sum((N_obs - np.mean(N_obs)) ** 2)\n",
    "        r2 = 1 - (ss_res / ss_tot)\n",
    "\n",
    "        if r2 > 0.6:\n",
    "            overall_r2 += r2\n",
    "            phase_models.append((t, N_obs, v_fit, r2))\n",
    "            \n",
    "            fit_results.append({\n",
    "                \"ID\": subset_id,\n",
    "                \"Phase\": i+1,\n",
    "                \"a\": v_fit['a'],\n",
    "                \"b\": v_fit['b'],\n",
    "                \"c\": v_fit['c'],\n",
    "                \"d\": v_fit['d'],\n",
    "                \"R²\": r2\n",
    "            })\n",
    "\n",
    "    # Evaluate overall fit result\n",
    "    if len(phase_models) > 0:\n",
    "        avg_r2 = overall_r2 / len(phase_models)\n",
    "        if avg_r2 > 0.6:\n",
    "            successful_fits.append(subset_id)\n",
    "\n",
    "            # Generate plots for first 5 successful subsets\n",
    "            if plot_count < max_plots:\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                colors = ['blue', 'green']\n",
    "                for j, (t, N_obs, v_fit, r2) in enumerate(phase_models):\n",
    "                    plt.scatter(t, N_obs, label=f\"Phase {j+1} Data\", color=colors[j % len(colors)], alpha=0.6)\n",
    "                    t_fine = np.linspace(min(t), max(t), 100)\n",
    "                    N_fine = v_fit['a'] * t_fine**3 + v_fit['b'] * t_fine**2 + v_fit['c'] * t_fine + v_fit['d']\n",
    "                    plt.plot(t_fine, N_fine, label=f\"Phase {j+1} (R²={r2:.3f})\", color=colors[j % len(colors)], linewidth=2)\n",
    "                    \n",
    "                plt.xlabel(\"Time\")\n",
    "                plt.ylabel(\"PopBio\")\n",
    "                plt.title(f\"NLLS Cubic Fit for ID: {subset_id[:30]}... (Avg R²={avg_r2:.3f})\")\n",
    "                plt.legend()\n",
    "\n",
    "                safe_id = sanitize_filename(subset_id)\n",
    "                plot_filename = os.path.join(plots_path, f\"fit_ID_{safe_id}.png\")\n",
    "                plt.savefig(plot_filename, dpi=300)\n",
    "                plt.close()\n",
    "\n",
    "                plot_count += 1\n",
    "\n",
    "# Save fit parameters to CSV\n",
    "fit_results_df = pd.DataFrame(fit_results)\n",
    "fit_results_df.to_csv(os.path.join(results_path, \"nlls_cubic_fits.csv\"), index=False)\n",
    "\n",
    "# Output successful fit count\n",
    "print(f\"\\n Number of successful two-stage NLLS cubic fits: {len(successful_fits)} / {len(subset_list)}\")\n",
    "print(f\" Fit parameters saved to: {results_path}/nlls_cubic_fits.csv.csv\")\n",
    "print(f\" Fit plots saved to: {plots_path} (only for the first 5 successful fits)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:36:56.200274Z",
     "iopub.status.busy": "2025-03-14T13:36:56.200145Z",
     "iopub.status.idle": "2025-03-14T13:37:01.368711Z",
     "shell.execute_reply": "2025-03-14T13:37:01.368354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Serratia marcescens_10_Pasteurised Skim Milk_Phillips, J.D. and Griffiths, M.W., 1987. The relation between temperature and growth of bacteria in dairy products. Food Microbiology, 4(2), pp.173-185. has too few data points, skipping\n",
      "⚠️ Serratia marcescens_10_UHT Skim Milk_Phillips, J.D. and Griffiths, M.W., 1987. The relation between temperature and growth of bacteria in dairy products. Food Microbiology, 4(2), pp.173-185. has too few data points, skipping\n",
      "⚠️ Serratia marcescens_15_Pasteurised Skim Milk_Phillips, J.D. and Griffiths, M.W., 1987. The relation between temperature and growth of bacteria in dairy products. Food Microbiology, 4(2), pp.173-185. has too few data points, skipping\n",
      "⚠️ Serratia marcescens_15_UHT Skim Milk_Phillips, J.D. and Griffiths, M.W., 1987. The relation between temperature and growth of bacteria in dairy products. Food Microbiology, 4(2), pp.173-185. has too few data points, skipping\n",
      "⚠️ Serratia marcescens_10_UHT Full-fat Milk_Phillips, J.D. and Griffiths, M.W., 1987. The relation between temperature and growth of bacteria in dairy products. Food Microbiology, 4(2), pp.173-185. has too few data points, skipping\n",
      "⚠️ Serratia marcescens_10_Pasteurised Double Cream_Phillips, J.D. and Griffiths, M.W., 1987. The relation between temperature and growth of bacteria in dairy products. Food Microbiology, 4(2), pp.173-185. has too few data points, skipping\n",
      "⚠️ Serratia marcescens_10_UHT Double Cream_Phillips, J.D. and Griffiths, M.W., 1987. The relation between temperature and growth of bacteria in dairy products. Food Microbiology, 4(2), pp.173-185. has too few data points, skipping\n",
      "⚠️ Pseudomonas sp._8_APT Broth_Stannard, C.J., Williams, A.P. and Gibbs, P.A., 1985. Temperature/growth relationships for psychrotrophic food-spoilage bacteria. Food Microbiology, 2(2), pp.115-122. has too few data points, skipping\n",
      "\n",
      " Number of successful Logistic NLLS fits: 236 / 285\n",
      " Fit parameters saved to: ../results/nlls_logistic_fits.csv\n",
      " Fit plots saved to: ../results/logistic_plots (only for the first 5 successful fits)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lmfit import Minimizer, Parameters\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "data_path = \"../data/LogisticGrowthData_Cleaned.csv\"\n",
    "results_path = \"../results\"\n",
    "plots_path = os.path.join(results_path, \"logistic_plots\")\n",
    "\n",
    "# Ensure storage directories exist\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "os.makedirs(plots_path, exist_ok=True)\n",
    "\n",
    "# Read data\n",
    "data_filtered = pd.read_csv(data_path)\n",
    "\n",
    "# Get all subset IDs\n",
    "subset_list = data_filtered[\"ID\"].unique()\n",
    "successful_fits = []\n",
    "fit_results = []\n",
    "max_plots = 5  # Limit number of plots\n",
    "plot_count = 0  \n",
    "\n",
    "# Process filename\n",
    "def sanitize_filename(text, max_length=50):\n",
    "    \"\"\"Clean filename by removing special characters and limiting length.\"\"\"\n",
    "    text = \"\".join(c if c.isalnum() or c in \"_-\" else \"_\" for c in text)\n",
    "    if len(text) > max_length:\n",
    "        text = text[:max_length]\n",
    "        hash_suffix = hashlib.md5(text.encode()).hexdigest()[:8]\n",
    "        text += f\"_{hash_suffix}\"\n",
    "    return text\n",
    "\n",
    "# Define Logistic Growth objective function\n",
    "def logistic_growth(params, t, data):\n",
    "    \"\"\"Logistic Growth model residuals.\"\"\"\n",
    "    v = params.valuesdict()\n",
    "    r_t = np.clip(v['r'] * t, -100, 100)  # Prevent overflow in r * t calculation\n",
    "    \n",
    "    model = (v['N_0'] * v['N_max'] * np.exp(r_t)) / \\\n",
    "            (v['N_max'] + v['N_0'] * (np.exp(r_t) - 1))\n",
    "    \n",
    "    if np.any(np.isnan(model)):\n",
    "        print(f\"⚠️ NaN detected in model calculation! Params: {v}\")\n",
    "    \n",
    "    return model - data  # Return residuals\n",
    "\n",
    "# Iterate over all subsets for NLLS fitting\n",
    "for subset_id in subset_list:\n",
    "    subset_data = data_filtered[data_filtered[\"ID\"] == subset_id]\n",
    "    \n",
    "    if len(subset_data) < 5:\n",
    "        print(f\"⚠️ {subset_id} has too few data points, skipping\")\n",
    "        continue\n",
    "\n",
    "    subset_data = subset_data.dropna(subset=[\"Time\", \"PopBio\"])\n",
    "    t = subset_data[\"Time\"].values\n",
    "    N_obs = subset_data[\"PopBio\"].values\n",
    "\n",
    "    if np.any(np.isnan(t)) or np.any(np.isnan(N_obs)):\n",
    "        print(f\"⚠️ {subset_id} contains NaN values, skipping\")\n",
    "        continue\n",
    "\n",
    "    # Set initial parameters\n",
    "    N_0_init = max(N_obs[0], 1e-3)  \n",
    "    N_max_init = max(N_obs[-1], N_obs[0] * 1.1)  \n",
    "    r_init = max((np.log(N_obs[-1]) - np.log(N_obs[0])) / (t[-1] - t[0]), 1e-3)  \n",
    "\n",
    "    # Create parameter object\n",
    "    params_logistic = Parameters()\n",
    "    params_logistic.add('N_0', value=N_0_init, min=0)\n",
    "    params_logistic.add('N_max', value=N_max_init, min=N_0_init)\n",
    "    params_logistic.add('r', value=r_init, min=0, max=1)  \n",
    "\n",
    "    # Perform NLLS fitting\n",
    "    minner = Minimizer(logistic_growth, params_logistic, fcn_args=(t, N_obs))\n",
    "    fit_logistic = minner.minimize(method='leastsq')\n",
    "\n",
    "    # Compute R²\n",
    "    v_fit = fit_logistic.params.valuesdict()\n",
    "    N_fit = (v_fit['N_0'] * v_fit['N_max'] * np.exp(v_fit['r'] * t)) / \\\n",
    "            (v_fit['N_max'] + v_fit['N_0'] * (np.exp(v_fit['r'] * t) - 1))\n",
    "\n",
    "    ss_res = np.sum((N_obs - N_fit) ** 2)\n",
    "    ss_tot = np.sum((N_obs - np.mean(N_obs)) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "\n",
    "    # Store fit parameters\n",
    "    fit_results.append({\n",
    "        \"ID\": subset_id,\n",
    "        \"N_0\": v_fit['N_0'],\n",
    "        \"N_max\": v_fit['N_max'],\n",
    "        \"r\": v_fit['r'],\n",
    "        \"R²\": r2\n",
    "    })\n",
    "\n",
    "    if r2 > 0.6:\n",
    "        successful_fits.append(subset_id)\n",
    "\n",
    "        # Generate plots for first 5 successful subsets\n",
    "        if plot_count < max_plots:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.scatter(t, N_obs, label=\"Observed Data\", color='blue', alpha=0.6)\n",
    "\n",
    "            # Generate smooth fit curve\n",
    "            t_fine = np.linspace(min(t), max(t), 100)\n",
    "            N_fine = (v_fit['N_0'] * v_fit['N_max'] * np.exp(v_fit['r'] * t_fine)) / \\\n",
    "                     (v_fit['N_max'] + v_fit['N_0'] * (np.exp(v_fit['r'] * t_fine) - 1))\n",
    "\n",
    "            plt.plot(t_fine, N_fine, label=f\"Logistic NLLS Fit (R²={r2:.3f})\", color='red', linewidth=2)\n",
    "            plt.xlabel(\"Time\")\n",
    "            plt.ylabel(\"PopBio\")\n",
    "            plt.title(f\"Logistic NLLS Fit for ID: {subset_id[:30]}...\")\n",
    "            plt.legend()\n",
    "\n",
    "            # Save plot\n",
    "            safe_id = sanitize_filename(subset_id)\n",
    "            plot_filename = os.path.join(plots_path, f\"fit_ID_{safe_id}.png\")\n",
    "            plt.savefig(plot_filename, dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "            plot_count += 1\n",
    "\n",
    "# Save fit parameters to CSV\n",
    "fit_results_df = pd.DataFrame(fit_results)\n",
    "fit_results_df.to_csv(os.path.join(results_path, \"nlls_logistic_fits.csv\"), index=False)\n",
    "\n",
    "# Output successful fit count\n",
    "print(f\"\\n Number of successful Logistic NLLS fits: {len(successful_fits)} / {len(subset_list)}\")\n",
    "print(f\" Fit parameters saved to: {results_path}/nlls_logistic_fits.csv\")\n",
    "print(f\" Fit plots saved to: {plots_path} (only for the first 5 successful fits)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:37:01.370649Z",
     "iopub.status.busy": "2025-03-14T13:37:01.370506Z",
     "iopub.status.idle": "2025-03-14T13:37:03.889813Z",
     "shell.execute_reply": "2025-03-14T13:37:03.889473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Serratia marcescens_10_Pasteurised Skim Milk_Phillips, J.D. and Griffiths, M.W., 1987. The relation between temperature and growth of bacteria in dairy products. Food Microbiology, 4(2), pp.173-185. has too few data points, skipping\n",
      "⚠️ Serratia marcescens_10_UHT Skim Milk_Phillips, J.D. and Griffiths, M.W., 1987. The relation between temperature and growth of bacteria in dairy products. Food Microbiology, 4(2), pp.173-185. has too few data points, skipping\n",
      "⚠️ Serratia marcescens_15_Pasteurised Skim Milk_Phillips, J.D. and Griffiths, M.W., 1987. The relation between temperature and growth of bacteria in dairy products. Food Microbiology, 4(2), pp.173-185. has too few data points, skipping\n",
      "⚠️ Serratia marcescens_15_UHT Skim Milk_Phillips, J.D. and Griffiths, M.W., 1987. The relation between temperature and growth of bacteria in dairy products. Food Microbiology, 4(2), pp.173-185. has too few data points, skipping\n",
      "⚠️ Serratia marcescens_10_UHT Full-fat Milk_Phillips, J.D. and Griffiths, M.W., 1987. The relation between temperature and growth of bacteria in dairy products. Food Microbiology, 4(2), pp.173-185. has too few data points, skipping\n",
      "⚠️ Serratia marcescens_10_Pasteurised Double Cream_Phillips, J.D. and Griffiths, M.W., 1987. The relation between temperature and growth of bacteria in dairy products. Food Microbiology, 4(2), pp.173-185. has too few data points, skipping\n",
      "⚠️ Serratia marcescens_10_UHT Double Cream_Phillips, J.D. and Griffiths, M.W., 1987. The relation between temperature and growth of bacteria in dairy products. Food Microbiology, 4(2), pp.173-185. has too few data points, skipping\n",
      "⚠️ Pseudomonas sp._8_APT Broth_Stannard, C.J., Williams, A.P. and Gibbs, P.A., 1985. Temperature/growth relationships for psychrotrophic food-spoilage bacteria. Food Microbiology, 2(2), pp.115-122. has too few data points, skipping\n",
      "\n",
      " Number of successful Gompertz model fits: 162 / 285\n",
      " Fit parameters saved to: ../results/nlls_gompertz_fits.csv\n",
      " Fit plots saved to: ../results/Gompertz_plots (only for the first 5 successful fits)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lmfit import Parameters, Minimizer\n",
    "\n",
    "# Load data\n",
    "data_path = \"../data/LogisticGrowthData_Cleaned.csv\"\n",
    "results_path = \"../results\"\n",
    "plots_path = os.path.join(results_path, \"Gompertz_plots\")\n",
    "\n",
    "# Ensure storage directories exist\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "os.makedirs(plots_path, exist_ok=True)\n",
    "\n",
    "# Read data\n",
    "data_filtered = pd.read_csv(data_path)\n",
    "\n",
    "# Get all subset IDs\n",
    "subset_list = data_filtered[\"ID\"].unique()\n",
    "successful_fits = []\n",
    "fit_results = []\n",
    "max_plots = 5  # Limit number of plots\n",
    "plot_count = 0  \n",
    "\n",
    "# Process filename\n",
    "def sanitize_filename(text, max_length=50):\n",
    "    \"\"\"Clean filename by removing special characters and limiting length.\"\"\"\n",
    "    text = \"\".join(c if c.isalnum() or c in \"_-\" else \"_\" for c in text)\n",
    "    if len(text) > max_length:\n",
    "        text = text[:max_length]\n",
    "        hash_suffix = hashlib.md5(text.encode()).hexdigest()[:8]\n",
    "        text += f\"_{hash_suffix}\"\n",
    "    return text\n",
    "\n",
    "# Define Gompertz Growth objective function\n",
    "def gompertz_residuals(params, t, data):\n",
    "    \"\"\"Gompertz growth model residuals.\"\"\"\n",
    "    v = params.valuesdict()\n",
    "    \n",
    "    exp_term = np.exp(np.clip(v['r_max'] * np.exp(1) * (v['t_lag'] - t) / \n",
    "               ((v['N_max'] - v['N_0']) * np.log(10)) + 1, -100, 100))\n",
    "    \n",
    "    model = v['N_0'] + (v['N_max'] - v['N_0']) * np.exp(-exp_term)\n",
    "\n",
    "    return model - data  # Compute residuals\n",
    "\n",
    "# Estimate initial values for Gompertz model\n",
    "def estimate_initial_values(t, popbio):\n",
    "    \"\"\"Estimate initial parameters for Gompertz model.\"\"\"\n",
    "    N_0_init = max(np.percentile(popbio, 5), 1e-3)  \n",
    "    N_max_init = max(np.percentile(popbio, 95), N_0_init * 1.1)  \n",
    "    \n",
    "    dydt = np.gradient(popbio, t)\n",
    "    r_max_init = np.clip(max(dydt) / (N_max_init - N_0_init), 0.001, 3)  \n",
    "    \n",
    "    t_lag_init = t[np.argmin(dydt)]  \n",
    "    \n",
    "    return N_0_init, N_max_init, r_max_init, t_lag_init\n",
    "\n",
    "# Batch fitting\n",
    "for subset in subset_list:\n",
    "    subset_data = data_filtered[data_filtered[\"ID\"] == subset]\n",
    "\n",
    "    if len(subset_data) < 5:  \n",
    "        print(f\"⚠️ {subset} has too few data points, skipping\")\n",
    "        continue\n",
    "\n",
    "    t = subset_data[\"Time\"].values\n",
    "    popbio = subset_data[\"PopBio\"].values\n",
    "\n",
    "    popbio = np.clip(popbio, 1e-3, None)\n",
    "\n",
    "    # Compute initial values\n",
    "    N_0_init, N_max_init, r_max_init, t_lag_init = estimate_initial_values(t, popbio)\n",
    "\n",
    "    # Create parameter object\n",
    "    params = Parameters()\n",
    "    params.add_many(\n",
    "        ('N_0', N_0_init, True, 1e-3, 10),\n",
    "        ('N_max', N_max_init, True, N_0_init * 1.1, 100),\n",
    "        ('r_max', r_max_init, True, 0.001, 3),\n",
    "        ('t_lag', t_lag_init, True, min(t), max(t))\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Perform NLLS fitting\n",
    "        minner = Minimizer(gompertz_residuals, params, fcn_args=(t, popbio))\n",
    "        fit_result = minner.minimize()\n",
    "\n",
    "        # Compute R²\n",
    "        fitted_values = gompertz_residuals(fit_result.params, t, np.zeros_like(popbio)) + popbio\n",
    "        ss_res = np.sum((popbio - fitted_values) ** 2)\n",
    "        ss_tot = np.sum((popbio - np.mean(popbio)) ** 2)\n",
    "        r2 = 1 - (ss_res / ss_tot)\n",
    "\n",
    "        # Store fit parameters\n",
    "        v_fit = fit_result.params.valuesdict()\n",
    "        fit_results.append({\n",
    "            \"ID\": subset,\n",
    "            \"N_0\": v_fit['N_0'],\n",
    "            \"N_max\": v_fit['N_max'],\n",
    "            \"r_max\": v_fit['r_max'],\n",
    "            \"t_lag\": v_fit['t_lag'],\n",
    "            \"R²\": r2\n",
    "        })\n",
    "\n",
    "        if r2 > 0.6:  \n",
    "            successful_fits.append(subset)\n",
    "\n",
    "            # Generate plots for first 5 successful subsets\n",
    "            if plot_count < max_plots:\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.scatter(t, popbio, label=\"Observed Data\", color=\"blue\", alpha=0.6)\n",
    "                plt.plot(t, fitted_values, label=f\"Gompertz Fit (R²={r2:.3f})\", color=\"red\")\n",
    "                plt.xlabel(\"Time\")\n",
    "                plt.ylabel(\"PopBio\")\n",
    "                plt.title(f\"Gompertz Model Fit for {subset[:30]}...\")\n",
    "                plt.legend()\n",
    "\n",
    "                # Save plot\n",
    "                safe_id = sanitize_filename(subset)\n",
    "                plot_filename = os.path.join(plots_path, f\"fit_ID_{safe_id}.png\")\n",
    "                plt.savefig(plot_filename, dpi=300)\n",
    "                plt.close()\n",
    "\n",
    "                plot_count += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ {subset} fitting failed: {e}\")\n",
    "        continue  \n",
    "\n",
    "# Save fit parameters to CSV\n",
    "fit_results_df = pd.DataFrame(fit_results)\n",
    "fit_results_df.to_csv(os.path.join(results_path, \"nlls_gompertz_fits.csv\"), index=False)\n",
    "\n",
    "# Output successful fit count\n",
    "print(f\"\\n Number of successful Gompertz model fits: {len(successful_fits)} / {len(subset_list)}\")\n",
    "print(f\" Fit parameters saved to: {results_path}/nlls_gompertz_fits.csv\")\n",
    "print(f\" Fit plots saved to: {plots_path} (only for the first 5 successful fits)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:37:03.891754Z",
     "iopub.status.busy": "2025-03-14T13:37:03.891581Z",
     "iopub.status.idle": "2025-03-14T13:37:04.053900Z",
     "shell.execute_reply": "2025-03-14T13:37:04.053565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated fitted plots and saved to PDF: ../results/random_combined_model_plot.pdf\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# Define file paths\n",
    "results_path = \"../results\"\n",
    "pdf_filename = \"random_combined_model_plot.pdf\"\n",
    "pdf_path = os.path.join(results_path, pdf_filename)  # Final PDF file path\n",
    "\n",
    "# Read model fitting results\n",
    "files = {\n",
    "    \"Quadratic\": \"nlls_quadratic_fits.csv\",\n",
    "    \"Cubic\": \"nlls_cubic_fits.csv\",\n",
    "    \"Logistic\": \"nlls_logistic_fits.csv\",\n",
    "    \"Gompertz\": \"nlls_gompertz_fits.csv\"\n",
    "}\n",
    "\n",
    "# Load all model fitting results\n",
    "model_fits = {model: pd.read_csv(os.path.join(results_path, file)) for model, file in files.items()}\n",
    "\n",
    "# Count the number of successful fits for each model\n",
    "success_counts = {model: len(df.dropna()) for model, df in model_fits.items()}\n",
    "\n",
    "# Identify subsets successfully fitted by all models\n",
    "all_models_fitted = set(model_fits[\"Quadratic\"][\"ID\"]).intersection(\n",
    "    set(model_fits[\"Cubic\"][\"ID\"]),\n",
    "    set(model_fits[\"Logistic\"][\"ID\"]),\n",
    "    set(model_fits[\"Gompertz\"][\"ID\"])\n",
    ")\n",
    "\n",
    "# Convert to list for random selection\n",
    "all_models_fitted = list(all_models_fitted)\n",
    "\n",
    "# Randomly select 5 subsets\n",
    "np.random.seed(42)  # Fix random seed for reproducibility\n",
    "selected_subsets = np.random.choice(all_models_fitted, 1, replace=False)\n",
    "\n",
    "# Load raw data\n",
    "data_path = \"../data/LogisticGrowthData_Cleaned.csv\"\n",
    "raw_data = pd.read_csv(data_path)\n",
    "\n",
    "# Create a PDF to save all plots\n",
    "with PdfPages(pdf_path) as pdf:\n",
    "    for subset_id in selected_subsets:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        \n",
    "        # Retrieve original data\n",
    "        subset_data = raw_data[raw_data[\"ID\"] == subset_id]\n",
    "        t = subset_data[\"Time\"].values\n",
    "        y_true = subset_data[\"PopBio\"].values\n",
    "        plt.scatter(t, y_true, label=\"Observed Data\", color='black', alpha=0.6)\n",
    "        \n",
    "        # Plot fitted curves for four models\n",
    "        for model_name, df in model_fits.items():\n",
    "            params_row = df[df[\"ID\"] == subset_id]\n",
    "            if params_row.empty:\n",
    "                continue  # Skip if fitting was unsuccessful\n",
    "            \n",
    "            # Generate prediction curve\n",
    "            t_fine = np.linspace(min(t), max(t), 100)\n",
    "            if model_name == \"Quadratic\":\n",
    "                y_pred = params_row[\"a\"].values[0] * t_fine**2 + params_row[\"b\"].values[0] * t_fine + params_row[\"c\"].values[0]\n",
    "            elif model_name == \"Cubic\":\n",
    "                y_pred = (params_row[\"a\"].values[0] * t_fine**3 + params_row[\"b\"].values[0] * t_fine**2 +\n",
    "                          params_row[\"c\"].values[0] * t_fine + params_row[\"d\"].values[0])\n",
    "            elif model_name == \"Logistic\":\n",
    "                N_0, N_max, r = params_row[\"N_0\"].values[0], params_row[\"N_max\"].values[0], params_row[\"r\"].values[0]\n",
    "                y_pred = (N_0 * N_max * np.exp(r * t_fine)) / (N_max + N_0 * (np.exp(r * t_fine) - 1))\n",
    "            elif model_name == \"Gompertz\":\n",
    "                N_0, N_max, r_max, t_lag = params_row[\"N_0\"].values[0], params_row[\"N_max\"].values[0], params_row[\"r_max\"].values[0], params_row[\"t_lag\"].values[0]\n",
    "                exp_term = np.exp(r_max * np.exp(1) * (t_lag - t_fine) / ((N_max - N_0) * np.log(10)) + 1)\n",
    "                y_pred = N_0 + (N_max - N_0) * np.exp(-exp_term)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            plt.plot(t_fine, y_pred, label=f\"{model_name} Fit\")\n",
    "\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"PopBio\")\n",
    "        plt.title(f\"Model Fit Comparison for {subset_id[:30]}...\")\n",
    "        plt.legend()\n",
    "        \n",
    "        # Save to PDF\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "\n",
    "print(f\"\\nGenerated fitted plots and saved to PDF: {pdf_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
